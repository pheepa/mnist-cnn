{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from time import time\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if train_on_gpu else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST('files/trainset', download=True, train=True, transform=transform)\n",
    "testset = datasets.MNIST('files/testset', download=True, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=4)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = iter(trainloader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 28, 28])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efff48db880>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[0].numpy().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv0 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5)\n",
    "        self.pool0 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv1_drop = nn.Dropout2d()\n",
    "        \n",
    "        self.fc0 = nn.Linear(in_features=1024, out_features=128)\n",
    "        self.fc1 = nn.Linear(in_features=128, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        c0 = F.relu(self.pool0(self.conv0(x)))\n",
    "        c1 = F.relu(self.pool1(self.conv1_drop(self.conv1(c0))))\n",
    "        \n",
    "        fl = c1.view(-1, 1024)\n",
    "        \n",
    "        f0 = F.relu(self.fc0(fl))\n",
    "        f1 = F.dropout(f0, training=self.training)\n",
    "        f2 = self.fc1(f1)\n",
    "        return F.log_softmax(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7efffdc3d030>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = 23\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, opt, loss_fn, epochs, data_tr, data_val):\n",
    "    X_val, Y_val = next(iter(data_val))\n",
    "    val_losses = []\n",
    "    train_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        tic = time()\n",
    "        print('* Epoch %d/%d' % (epoch+1, epochs))\n",
    "\n",
    "        avg_loss = 0\n",
    "        model.train()  # train mode\n",
    "        for X_batch, Y_batch in tqdm(data_tr):\n",
    "            # data to device\n",
    "            X_batch = X_batch.to(device)\n",
    "            Y_batch = Y_batch.to(device)\n",
    "            # set parameter gradients to zero\n",
    "            opt.zero_grad()\n",
    "            # forward\n",
    "            Y_pred = model(X_batch)\n",
    "            \n",
    "            loss = loss_fn(Y_pred, Y_batch) # forward-pass\n",
    "            loss.backward()  # backward-pass\n",
    "            opt.step()  # update weights\n",
    "\n",
    "            # calculate loss to show the user\n",
    "            avg_loss += loss / len(data_tr)\n",
    "        toc = time()\n",
    "        print('loss: %f' % avg_loss)\n",
    "        train_losses.append(avg_loss)\n",
    "        \n",
    "        # show intermediate results\n",
    "        model.eval()  # testing mode\n",
    "        with torch.no_grad():\n",
    "            Y_hat = model(X_val.to(device)).detach().cpu()\n",
    "            val_loss = loss_fn(Y_hat, Y_val)\n",
    "            val_losses.append(val_loss)\n",
    "            \n",
    "        # Visualize tools        \n",
    "        \n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "# criterion = nn.NLLLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv1): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv1_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc0): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  (fc1): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-a490a351be76>:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(f2)\n",
      "100%|██████████| 1875/1875 [00:15<00:00, 117.82it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.479258\n",
      "* Epoch 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:15<00:00, 118.65it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.156240\n",
      "* Epoch 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:15<00:00, 118.73it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.119330\n",
      "* Epoch 4/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:15<00:00, 118.80it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.098440\n",
      "* Epoch 5/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:15<00:00, 118.61it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.087773\n",
      "* Epoch 6/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:15<00:00, 118.27it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.081533\n",
      "* Epoch 7/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:15<00:00, 118.62it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.073058\n",
      "* Epoch 8/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:15<00:00, 118.54it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.070308\n",
      "* Epoch 9/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:15<00:00, 118.47it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.065161\n",
      "* Epoch 10/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:15<00:00, 118.77it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.061349\n",
      "* Epoch 11/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:15<00:00, 118.21it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.059131\n",
      "* Epoch 12/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:15<00:00, 118.72it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.054078\n",
      "* Epoch 13/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:15<00:00, 118.61it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.051580\n",
      "* Epoch 14/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:15<00:00, 118.51it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.051740\n",
      "* Epoch 15/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 232/1875 [00:02<00:14, 115.72it/s]"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = train(model=model, opt=optimizer, loss_fn=criterion, epochs=15, data_tr=trainloader, data_val=testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chanhing of loss on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 15, num=15)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "plt.plot(x, train_losses, color='green', marker='o')\n",
    "\n",
    "fig.suptitle('History of loss on train data', fontsize=20)\n",
    "plt.xlabel('epoch', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=16)\n",
    "fig.savefig('results/train_loss.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chanhing of loss on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 15, num=15)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "plt.plot(x, val_losses, color='m', marker='o')\n",
    "\n",
    "fig.suptitle('History of loss on test data', fontsize=20)\n",
    "plt.xlabel('epoch', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=16)\n",
    "fig.savefig('results/test_loss.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, testloader):\n",
    "    accuracy = 0.\n",
    "    count_all = 0\n",
    "    for X_val, Y_val in testloader:\n",
    "        count_all += len(Y_val)\n",
    "        Y_pred = model(X_val.to(device))\n",
    "        Y_pred = torch.argmax(Y_pred, 1).to('cpu')\n",
    "        true_predicted = (Y_pred == Y_val).sum()\n",
    "        accuracy += true_predicted\n",
    "    accuracy /= count_all\n",
    "    return accuracy.numpy().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = test(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy: {:.3f}%'.format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, Y_val = next(iter(testloader))\n",
    "Y_pred = model(X_val.to(device))\n",
    "Y_pred = torch.argmax(Y_pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=10\n",
    "h=10\n",
    "fig=plt.figure(figsize=(16, 16))\n",
    "columns = 4\n",
    "rows = 4\n",
    "for i in range(1, columns*rows +1):\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(X_val[i].numpy().squeeze(), cmap='gray')\n",
    "    plt.title('real: {}, predicted: {}'.format(Y_val[i].item(), Y_pred[i].item()))\n",
    "fig.savefig('results/test.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mnist-cnn-env]",
   "language": "python",
   "name": "conda-env-mnist-cnn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
